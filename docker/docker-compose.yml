version: "3.8"

services:
  # -----------------------------
  # Ollama LLM server
  # -----------------------------
  ollama:
    build:
      context: ./ollama-server
      dockerfile: Dockerfile
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/health"]
      interval: 10s
      retries: 5

  # -----------------------------
  # PostgreSQL database for Django
  # -----------------------------
  db:
    image: postgres:15
    environment:
      POSTGRES_USER: omnibioai
      POSTGRES_PASSWORD: secretpassword
      POSTGRES_DB: omnibioai
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER}"]
      interval: 10s
      retries: 5

  # -----------------------------
  # Redis (for Celery & caching)
  # -----------------------------
  redis:
    image: redis:7
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      retries: 5

  # -----------------------------
  # Django Web Application
  # -----------------------------
  webapp:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    depends_on:
      ollama:
        condition: service_healthy
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DEBUG: '0'
      SECRET_KEY: 'supersecretkey'
      DATABASE_URL: postgres://omnibioai:secretpassword@db:5432/omnibioai
      REDIS_URL: redis://redis:6379
      OLLAMA_ENDPOINT: http://ollama:11434/api/generate
    volumes:
      - static_volume:/app/staticfiles
      - media_volume:/app/media
      - logs:/app/logs
    command:
      [
        "./wait-for-service.sh", "ollama", "11434", "60", "--",
        "./wait-for-service.sh", "db", "5432", "60", "--",
        "./wait-for-service.sh", "redis", "6379", "60", "--",
        "gunicorn", "omnibioai.wsgi:application", "--bind", "0.0.0.0:8000", "--workers", "3"
      ]
    restart: unless-stopped

  # -----------------------------
  # Celery Worker - runs async tasks + pipelines
  # -----------------------------
  celery:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      webapp:
        condition: service_started
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: postgres://omnibioai:secretpassword@db:5432/omnibioai
      REDIS_URL: redis://redis:6379
    command: ["celery", "-A", "omnibioai", "worker", "--loglevel=INFO"]
    volumes:
      - workflows:/app/workflows
      - logs:/app/logs
    restart: unless-stopped

  # -----------------------------
  # Celery Beat - schedules tasks
  # -----------------------------
  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      redis:
        condition: service_healthy
    environment:
      REDIS_URL: redis://redis:6379
    command: ["celery", "-A", "omnibioai", "beat", "--loglevel=INFO"]
    restart: unless-stopped

  # -----------------------------
  # Workflow Runner (Nextflow, Snakemake, WDL)
  # -----------------------------
  workflow_runner:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      redis:
        condition: service_healthy
      webapp:
        condition: service_started
    environment:
      WORKFLOW_HOME: /app/workflows
      REDIS_URL: redis://redis:6379
    volumes:
      - workflows:/app/workflows
      - workflow_runs:/app/workflow_runs
      - logs:/app/logs
    command: ["sleep", "infinity"]
    restart: unless-stopped

# -----------------------------
# Volumes
# -----------------------------
volumes:
  ollama_data:
  pgdata:
  redis_data:
  static_volume:
  media_volume:
  logs:
  workflows:
  workflow_runs:
